##Public Datasets Archive


- CFDR  
https://www.usenix.org/cfdr  
The computer failure data repository (CFDR) aims at accelerating research on system reliability by filling the nearly empty collection of public data with detailed failure data from a variety of large production systems.


- Los Alamos National Lab's HPC-5 data  
http://institute.lanl.gov/data/  
**Not available anymore.** For hecfsio and hpc data related issues contact ggrider@lanl.gov.


- FAILURE TRACE ARCHIVE  
http://fta.scem.uws.edu.au/index.php?n=Main.DataSets  
The Failure Trace Archive (FTA) is centralized public repository of availability traces of distributed systems, and tools for their analysis. The purpose of this archive is to facilitate the design, validation, and comparison of fault-tolerant models and algorithms.


- The linked Web APIs dataset  
http://linked-web-apis.fit.cvut.cz/  
The Linked Web APIs dataset is a Linked Data dataset with semantic descriptions about Web APIs. It contains over 11,339 of Web APIs descriptions, over 7,415 mashups and almost 7,717 mashup developers' profiles. The data is retrieved from ProgrammableWeb.com, the largest Web service and mashup repository. In total the datasets contain over half million of RDF triples.

- Parallel workloads archive  
http://www.cs.huji.ac.il/labs/parallel/workload/  
This page contains a repository of information regarding the workloads on parallel machines. It has two main parts: raw workload logs from various machines around the world, and workload models (sometimes derived from these logs). The goal is to make this information freely available to researchers interested in the evaluation of parallel systems, and specifically schedulers for such systems. In addition, there is a bibliographical listing of papers related to workload issues, with a focus on papers using the available logs and models.


- Internet traffic archive: http://ita.ee.lbl.gov/html/traces.html  
The Internet Traffic Archive is a moderated repository to support widespread access to traces of Internet network traffic, sponsored by ACM SIGCOMM. The traces can be used to study network dynamics, usage characteristics, and growth patterns, as well as providing the grist for trace-driven simulations. The archive is also open to programs for reducing raw trace data to more manageable forms, for generating synthetic traces, and for analyzing traces. 


- Google Cluster Data: https://github.com/google/cluster-data  
Google trace records machine add/leave events, machine cpu/memory capacity, job begin/update/kill/finish event, task begin/update/kill/finish event, task preference, task cpu usage etc. The first version is a short trace that describes a 7 hour period from one cell (cluster). **Deprecated**. The second version provides data from an 12.5k-machine cell over about a month-long period in May 2011.


- The Grid Workloads Archive: http://gwa.ewi.tudelft.nl/  
The primary purpose of the Grid Workloads Archive is to provide (anonymized) workload traces from grid environments to researchers and to practitioners alike.


- CAIDA Data  
http://www.caida.org/data/overview/  
CAIDA collects several different types of data at geographically and topologically diverse locations, and makes this data available to the research community to the extent possible while preserving the privacy of individuals and organizations who donate data or network access.

